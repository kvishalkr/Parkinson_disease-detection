{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ON_fWP6_-WPZ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "\n",
    "# BASE_DIR = Path('../input/birdsong-recognition')\n",
    "# train_df = pd.read_csv(BASE_DIR / 'train.csv')\n",
    "# random_row = train_df.sample().squeeze()\n",
    "\n",
    "\n",
    "class SNRSegmenter(object):\n",
    "\n",
    "    def __init__(self, sample_rate, segment_len_ms, hop_len_ms, noise_len_ms, call_snr):\n",
    "        self.segment_len_samples = int(sample_rate * segment_len_ms / 1000)\n",
    "        self.hop_len_samples = int(sample_rate * hop_len_ms / 1000)\n",
    "        self.noise_len_samples = int(sample_rate * noise_len_ms / 1000)\n",
    "\n",
    "        self.call_snr = call_snr\n",
    "\n",
    "    def _get_noise_level(self, sample):\n",
    "        abs_max = []\n",
    "\n",
    "        if len(sample) > self.noise_len_samples:\n",
    "            idx = 0\n",
    "            while idx + self.noise_len_samples < len(sample):\n",
    "                abs_max.append(np.max(np.abs(sample[idx:(idx+self.noise_len_samples)])))\n",
    "                idx += self.noise_len_samples\n",
    "        else:\n",
    "            abs_max.append(np.max(np.abs(sample)))\n",
    "\n",
    "        return min(abs_max)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        noise_level = self._get_noise_level(sample)\n",
    "\n",
    "        call_segments = []\n",
    "        call_snrs = []\n",
    "        \n",
    "        if len(sample) > self.segment_len_samples:\n",
    "            idx = 0\n",
    "            while idx + self.segment_len_samples < len(sample):\n",
    "                segment = sample[idx:(idx+self.segment_len_samples)]\n",
    "                seg_abs_max = np.max(np.abs(segment))\n",
    "                if seg_abs_max / noise_level > self.call_snr:\n",
    "                    call_segments.append(segment)\n",
    "                    call_snrs.append(seg_abs_max / noise_level)\n",
    "\n",
    "                idx += self.hop_len_samples\n",
    "\n",
    "        return call_segments, call_snrs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vishal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_io in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in c:\\users\\vishal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_io) (0.31.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_masking(audio, mask_duration):\n",
    "    start_point = np.random.randint(0, len(audio) - mask_duration)\n",
    "    audio[start_point:start_point + mask_duration] = 0\n",
    "    return audio\n",
    "\n",
    "def frequency_masking(audio, mask_range):\n",
    "    start_bin = np.random.randint(0, mask_range)\n",
    "    end_bin = min(start_bin + mask_range, audio.shape[0])\n",
    "    audio[start_bin:end_bin] = 0\n",
    "    return audio\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:/Users/Vishal/Desktop/btps8e02/Dataset/MDVRKCL\"\n",
    "\n",
    "path2 = \"C:/Users/Vishal/Desktop/btps8e02/Codes/VGGPD/dataset/hl4\"\n",
    "\n",
    "\n",
    "root = os.listdir(directory_path)\n",
    "\n",
    "for entry in root:\n",
    "    # print(entry)\n",
    "    subdir_path = os.path.join(directory_path, entry) #  create the absolute path of the subdir\n",
    "    subdir_path2 = os.path.join(path2, entry)\n",
    "    # print(subdir_path)\n",
    "    if os.path.isdir(subdir_path):  # check if it is a folder\n",
    "        subdir_entries = os.listdir(subdir_path)  # get the content of the subdir\n",
    "        for subentry in subdir_entries:\n",
    "            wav_file = os.path.join(subdir_path, subentry)  # absolute path of the subentry\n",
    "            y, sample_rate = librosa.load(wav_file)\n",
    "            # Calculate the current DC offset (mean of the audio signal)\n",
    "            dc_offset = np.mean(y)\n",
    "\n",
    "# Apply the DC shift\n",
    "            y_shifted = y - dc_offset\n",
    "\n",
    "            audio = librosa.util.normalize(y_shifted)\n",
    "            segment_len_ms = 4000\n",
    "            hop_len_ms = 4000\n",
    "            noise_len_ms = 500\n",
    "            call_snr_thresh = 5\n",
    "\n",
    "            segmenter = SNRSegmenter(sample_rate, segment_len_ms, hop_len_ms, noise_len_ms, call_snr_thresh)\n",
    "\n",
    "            calls, call_snrs = segmenter(audio)\n",
    "            h=1\n",
    "            for i in calls:\n",
    "                if len(subentry)>18:\n",
    "                    temp = subentry[:13]+ \"_2\"\n",
    "                else:\n",
    "                    temp = subentry[:13]+ \"_1\"\n",
    "                if entry == 'disease':\n",
    "                    temp = temp+'_1_'\n",
    "                else :\n",
    "                    temp = temp + '_0_'\n",
    "\n",
    "                temp_path = \"\"\n",
    "                if(subentry[12]=='0'):\n",
    "                    temp_path =  os.path.join(path2, 'UPDRS0')\n",
    "                else :\n",
    "                    temp_path =  os.path.join(path2, 'UPDRS1')\n",
    "\n",
    "\n",
    "                \n",
    "                file = os.path.join(subdir_path2, temp)\n",
    "                file2 = os.path.join(temp_path, temp)\n",
    "                # if(subentry[:4]=='ID05'):\n",
    "                #     print(len(subentry))\n",
    "                #     print(file)\n",
    "                sf.write(file+str(h)+\".wav\",i,sample_rate)\n",
    "                sf.write(file2+str(h)+\".wav\",i,sample_rate)\n",
    "                h = h+1\n",
    "\n",
    "            # here you can check everything you want for example if the subentry has a specific name etc\n",
    "            #print(subentry_path)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:/Users/Vishal/Downloads/ab/disease\"\n",
    "path2 = \"C:/Users/Vishal/Downloads/ac\"\n",
    "\n",
    "root = os.listdir(directory_path)\n",
    "\n",
    "\n",
    "for entry in root:\n",
    "    # print(entry)\n",
    "    wav_file = os.path.join(directory_path, entry)  # absolute path of the subentry\n",
    "    #p2 = os.path.join(path2, entry)\n",
    "    y, sample_rate = librosa.load(wav_file)\n",
    "\n",
    "    # Calculate the current DC offset (mean of the audio signal)\n",
    "    dc_offset = np.mean(y)\n",
    "    # Apply the DC shift\n",
    "    y_shifted = y - dc_offset\n",
    "    # Applying Normalization\n",
    "    audio = librosa.util.normalize(y_shifted)\n",
    "\n",
    "    masked_audio = time_masking(audio, mask_duration=100) \n",
    "    mask_audio = frequency_masking(audio, mask_range=10)\n",
    "    noise_added_signal = add_white_noise(audio,0.1)\n",
    "    pitch_scaleup_signal = pitch_scale(audio,sample_rate,4) #scaling up by 4\n",
    "    pitch_scaledown_signal = pitch_scale(audio,sample_rate,-4) #scaling down by 4\n",
    "    random_gained_signal = random_gain(audio,2,4)\n",
    "    inverted_signal  =polarity_inversion(audio)\n",
    "\n",
    "    \n",
    "    dt =1\n",
    "    if(int(entry[8])==2):\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaleup_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaledown_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,random_gained_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "\n",
    "    elif(int(entry[8])==3):\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaleup_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaledown_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,random_gained_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,noise_added_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,inverted_signal,sample_rate)\n",
    "    \n",
    "    else:\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaleup_signal,sample_rate)\n",
    "        dv= int(dt)+1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,pitch_scaledown_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,random_gained_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,noise_added_signal,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,inverted_signal,sample_rate)\n",
    "        masked_audio = time_masking(audio, mask_duration=100) \n",
    "        mask_audio = frequency_masking(audio, mask_range=10)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "        masked_audio = time_masking(audio, mask_duration=100) \n",
    "        mask_audio = frequency_masking(audio, mask_range=10)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "        masked_audio = time_masking(audio, mask_duration=100) \n",
    "        mask_audio = frequency_masking(audio, mask_range=10)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,mask_audio,sample_rate)\n",
    "        dt+=1\n",
    "        dv = entry[:-3] + '_' + str(dt) +'_.wav'\n",
    "        sf.write(dv,masked_audio,sample_rate)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:/Users/Vishal/Downloads/ab/healthy\"\n",
    "path2 = \"C:/Users/Vishal/Downloads/ac\"\n",
    "\n",
    "root = os.listdir(directory_path)\n",
    "dt =1\n",
    "\n",
    "for entry in root:\n",
    "    # print(entry)\n",
    "    wav_file = os.path.join(directory_path, entry)  # absolute path of the subentry\n",
    "    #p2 = os.path.join(path2, entry)\n",
    "    y, sample_rate = librosa.load(wav_file)\n",
    "            # Calculate the current DC offset (mean of the audio signal)\n",
    "    dc_offset = np.mean(y)\n",
    "\n",
    "# Apply the DC shift\n",
    "    y_shifted = y - dc_offset\n",
    "    audio = librosa.util.normalize(y_shifted)\n",
    "    masked_audio = time_masking(audio, mask_duration=100) \n",
    "    mask_audio = frequency_masking(audio, mask_range=10)\n",
    "    \n",
    "    dv = entry[:-4] + '_1_.wav'\n",
    "    file = os.path.join(path2,dv)\n",
    "    \n",
    "    if dt%2 ==1:\n",
    "\n",
    "\n",
    "                    #print(file)\n",
    "        sf.write(file,mask_audio,sample_rate)\n",
    "    else:\n",
    "        sf.write(file,masked_audio,sample_rate)\n",
    "    dt+=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch scaling\n",
    "def pitch_scale(signal,sample_rate,no_of_semitones):# no of semitones we want to scale up or down\n",
    "  return librosa.effects.pitch_shift(signal,sr =sample_rate,n_steps =no_of_semitones)\n",
    "# polarity inversion // not so useful augmentation technique\n",
    "def polarity_inversion(signal):\n",
    "  return signal*-1\n",
    "# adding white noise\n",
    "def add_white_noise(signal, noise_percentage_factor):\n",
    "    noise = np.random.normal(0, signal.std(), signal.size)\n",
    "    augmented_signal = signal + noise * noise_percentage_factor\n",
    "    return augmented_signal\n",
    "# random gain // scale up the amplitude by some factor\n",
    "def random_gain(signal, min_factor, max_factor):\n",
    "    gain_rate = np.random.uniform(min_factor, max_factor)\n",
    "    augmented_signal = signal * gain_rate\n",
    "    return augmented_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (299077376.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    time_stretched_signal = time_stretch(signal,0.8)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    " # _plot_signal_and_augmented_signal(signal,noise_added_signal,sample_rate)\n",
    "  time_stretched_signal = time_stretch(signal,0.8)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_masked_audio = time_masking(audio, mask_duration=100) \n",
    "freq_mask_audio = frequency_masking(audio, mask_range=10)\n",
    "noise_added_signal = add_white_noise(audio,0.1)\n",
    "pitch_scaleup_signal = pitch_scale(audio,sample_rate,4) #scaling up by 4\n",
    "pitch_scaledown_signal = pitch_scale(audio,sample_rate,-4) #scaling down by 4\n",
    "random_gained_signal = random_gain(audio,2,4)\n",
    "inverted_signal  =polarity_inversion(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"C:/Users/Vishal/Desktop/btps8e02/Dataset/MDVRKCL\"\n",
    "\n",
    "path2 = \"C:/Users/Vishal/Desktop/btps8e02/Codes/VGGPD/dataset\"\n",
    "\n",
    "\n",
    "root = os.listdir(directory_path)\n",
    "\n",
    "for entry in root:\n",
    "    # print(entry)\n",
    "    subdir_path = os.path.join(directory_path, entry) #  create the absolute path of the subdir\n",
    "    subdir_path2 = os.path.join(path2, entry)\n",
    "    # print(subdir_path)\n",
    "    if os.path.isdir(subdir_path):  # check if it is a folder\n",
    "        subdir_entries = os.listdir(subdir_path)  # get the content of the subdir\n",
    "        for subentry in subdir_entries:\n",
    "            wav_file = os.path.join(subdir_path, subentry)  # absolute path of the subentry\n",
    "            y, sample_rate = librosa.load(wav_file)\n",
    "            # Calculate the current DC offset (mean of the audio signal)\n",
    "            dc_offset = np.mean(y)\n",
    "\n",
    "# Apply the DC shift\n",
    "            y_shifted = y - dc_offset\n",
    "\n",
    "            audio = librosa.util.normalize(y_shifted)\n",
    "            segment_len_ms = 4000\n",
    "            hop_len_ms = 1000\n",
    "            noise_len_ms = 500\n",
    "            call_snr_thresh = 5\n",
    "\n",
    "            segmenter = SNRSegmenter(sample_rate, segment_len_ms, hop_len_ms, noise_len_ms, call_snr_thresh)\n",
    "\n",
    "            calls, call_snrs = segmenter(audio)\n",
    "            h=1\n",
    "            for i in calls:\n",
    "                if len(subentry)>18:\n",
    "                    temp = subentry[:13]+ \"_2_\"\n",
    "                else:\n",
    "                    temp = subentry[:13]+ \"_1_\"\n",
    "                file = os.path.join(subdir_path2, temp)\n",
    "                # if(subentry[:4]=='ID05'):\n",
    "                #     print(len(subentry))\n",
    "                #     print(file)\n",
    "                sf.write(file+str(h)+\".wav\",i,sample_rate)\n",
    "                h = h+1\n",
    "\n",
    "            # here you can check everything you want for example if the subentry has a specific name etc\n",
    "            #print(subentry_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ams = [0]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"C:/Users/Vishal/Downloads/aa\"\n",
    "path2 = \"C:/Users/Vishal/Downloads/ab\"\n",
    "\n",
    "root = os.listdir(path2)\n",
    "\n",
    "for entry in root:\n",
    "    # print(entry)\n",
    "     #  create the absolute path of the subdir\n",
    "    subdir_path2 = os.path.join(path2, entry)\n",
    "    if os.path.isdir(subdir_path2):  # check if it is a folder\n",
    "        subdir_entries = os.listdir(subdir_path2)  # get the content of the subdir\n",
    "        for subentry in subdir_entries:\n",
    "            #print(subentry[8])\n",
    "            ams[int(subentry[8])]+=1\n",
    "            \n",
    "\n",
    "\n",
    "            # here you can check everything you want for example if the subentry has a specific name etc\n",
    "            #print(subentry_path)\n",
    "            # if os.path.isdir(subentry_path):  # check if it is a folder\n",
    "            #     subdir_entriez = os.listdir(subentry_path)\n",
    "            #     for entry in subdir_entriez:\n",
    "            #       wav_file = os.path.join(subentry_path, entry)\n",
    "            #       # print(wav_file)\n",
    "            #       if(wav_file[-3:]=='wav'):\n",
    "            #         audio, sr = librosa.load(wav_file)\n",
    "            #         arr = np.array(mfcc(audio,sr))\n",
    "            #         np.savetxt(wav_file.replace('.wav', '_mfcc.txt'), arr, fmt=\"%d\")\n",
    "            #       # with open(wav_file.replace('wav', 'txt'), 'w') as filehandle:\n",
    "            #       #   json.dump(arr.toList(), filehandle)\n",
    "                 \n",
    "            #       # with open(wav_file.replace('wav', 'txt'), \"w\") as txt_file:\n",
    "            #       #   for line in arr:\n",
    "            #       #     txt_file.write(\" \".join(line) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2434, 0, 818, 567, 130, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_csv_path = \"normalized_mfcc_features.csv\"\n",
    "with open(output_csv_path, 'w') as file:\n",
    "    # Write the header\n",
    "    header = 'filename,' + ','.join([f'mfcc_{i}' for i in range(normalized_mfcc.shape[1])])\n",
    "    file.write(header + '\\n')\n",
    "\n",
    "    # Write the data\n",
    "    for fname, mfcc_row in zip(filenames, normalized_mfcc):\n",
    "        row = fname + ',' + ','.join(map(str, mfcc_row))\n",
    "        file.write(row + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "HG5mAIbv-nxa",
    "outputId": "83c86b38-99d9-4ea6-b85f-eaa999798d9b"
   },
   "outputs": [],
   "source": [
    "plt.title(f'SNR = {call_snrs[1]}')\n",
    "plt.plot(calls[0])\n",
    "ipd.display(ipd.Audio(calls[10], rate=sample_rate))\n",
    "\n",
    "\n",
    "# combined = ipd.Audio(calls[i], rate=sample_rate)\n",
    "# combined =  combined-combined\n",
    "# for i in calls:\n",
    "#   # i\n",
    "#   combined = combined + ipd.Audio(calls[i], rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6PWQ2dN-zGB"
   },
   "outputs": [],
   "source": [
    "concatenated_audio = b''.join(calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZnPkm0Mb_ELm",
    "outputId": "e1a8bab1-3b8f-41f7-a512-1aba20c131c5"
   },
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(concatenated_audio, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "RluJisURyYdS",
    "outputId": "cd91f703-d940-40c9-cf56-758ffdd8d21a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-db362192b927>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the first audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconcatenated_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the first audio file\n",
    "concatenated_audio = AudioSegment.from_file(calls[0])\n",
    "\n",
    "# Iterate over the remaining audio files\n",
    "for audio_file in calls[1:]:\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "    conctenated_audio += audio\n",
    "\n",
    "# Export the concatenated audio file\n",
    "conctenated_audio.export(\"concatenated.wav\", format=\"wav\")\n",
    "\n",
    "# Play the concatenated audio file\n",
    "ipd.display(ipd.Audio('concatenated.wav'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPigem7iyjvD",
    "outputId": "8fa65360-cdf9-48b2-d556-6a8021f081a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "pip install pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoqspIOLywbJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
